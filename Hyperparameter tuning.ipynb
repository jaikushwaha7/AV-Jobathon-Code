{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific computing libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data mining libaries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA#, FastICA\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, learning_curve\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#plot libaries\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True) # to show plots in notebook\n",
    "\n",
    "# online plotly\n",
    "#from plotly.plotly import plot, iplot\n",
    "#plotly.tools.set_credentials_file(username='XXXXXXXXXXXXXXX', api_key='XXXXXXXXXXXXXXX')\n",
    "\n",
    "# offline plotly\n",
    "from plotly.offline import plot, iplot\n",
    "\n",
    "# do not show any warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 17 # specify seed for reproducable results\n",
    "pd.set_option('display.max_columns', None) # prevents abbreviation (with '...') of columns in prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_FOREST_PARAMS = {\n",
    "    'clf__max_depth': [25, 50, 75],\n",
    "    'clf__max_features': [\"sqrt\"], # just sqrt is used because values of log2 and sqrt are very similar for our number of features (10-19) \n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__n_estimators': [100, 300, 500, 1000]\n",
    "}\n",
    "\n",
    "DECISION_TREE_PARAMS = {\n",
    "    'clf__max_depth': [25, 50, 75],\n",
    "    'clf__max_features': [\"sqrt\"], # just sqrt is used because values of log2 and sqrt are very similar for our number of features (10-19)\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__min_samples_split': [6, 10, 14],\n",
    "}\n",
    "\n",
    "LOGISTIC_REGRESSION_PARAMS = {\n",
    "    'clf__solver': ['liblinear'],\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__penalty': ['l2', 'l1']\n",
    "}\n",
    "\n",
    "KNN_PARAMS = {\n",
    "    'clf__n_neighbors': [5, 15, 25, 35, 45, 55, 65],\n",
    "    'clf__weights': ['uniform', 'distance'],\n",
    "    'clf__p': [1, 2, 10]\n",
    "}\n",
    "\n",
    "KNN_PARAMS_UNIFORM = {\n",
    "    'clf__n_neighbors': [5, 15, 25, 35, 45, 55, 65],\n",
    "    'clf__weights': ['uniform'],\n",
    "    'clf__p': [1, 2, 10]\n",
    "}\n",
    "\n",
    "SVM_PARAMS = [\n",
    "{\n",
    "    'clf__kernel': ['linear'],\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "}, \n",
    "{\n",
    "    'clf__kernel': ['rbf'],\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__gamma': [0.01, 0.1, 1, 10, 100],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the best grid search scores along with their parameters.\n",
    "def print_best_grid_search_scores_with_params(grid_search, n=5):\n",
    "    if not hasattr(grid_search, 'best_score_'):\n",
    "        raise KeyError('grid_search is not fitted.')\n",
    "    print(\"Best grid scores on validation set:\")\n",
    "    indexes = np.argsort(grid_search.cv_results_['mean_test_score'])[::-1][:n]\n",
    "    means = grid_search.cv_results_['mean_test_score'][indexes]\n",
    "    stds = grid_search.cv_results_['std_test_score'][indexes]\n",
    "    params = np.array(grid_search.cv_results_['params'])[indexes]\n",
    "    for mean, std, params in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gridsearch_with_cv\n",
    "def do_gridsearch_with_cv(clf, params, X_train, y_train, cv, smote=None):\n",
    "\n",
    "    if smote is None:\n",
    "        pipeline = Pipeline([('clf', clf)])\n",
    "    else:\n",
    "        pipeline = Pipeline([('sm', sm), ('clf', clf)])\n",
    "        \n",
    "    gs = GridSearchCV(pipeline, params, cv=kf, scoring='f1', return_train_score=True)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs\n",
    "\n",
    "def score_on_test_set(clfs, datasets):\n",
    "    scores = []\n",
    "    for c, (X_test, y_test) in zip(clfs, datasets):\n",
    "        scores.append(c.score(X_test, y_test))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set in proportion 4:1 for all differntly preprocessed datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_normed, df_y, test_size=0.2, random_state=SEED)\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(df_X_reduced, df_y, test_size=0.2, random_state=SEED)\n",
    "cols_without_duplicate = [x for x in df_X_normed.columns if x not in duplicate_features]\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(df_X_normed[cols_without_duplicate], df_y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the full train dataset:\", X_train.shape)\n",
    "print(\"Shape of the train dataset with reduced features\", X_train_red.shape)\n",
    "print(\"Shape of the transformed train dataset using the first 22 Principal Components\", X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=SEED)\n",
    "kf = StratifiedKFold(n_splits=5, random_state=SEED)\n",
    "clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "clf_balanced = RandomForestClassifier(random_state=SEED, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs_full = do_gridsearch_with_cv(clf_rf, RANDOM_FOREST_PARAMS, X_train, y_train, kf, smote=None)\n",
    "gs_red = do_gridsearch_with_cv(clf_rf, RANDOM_FOREST_PARAMS, X_train_red, y_train_red, kf, smote=None)\n",
    "gs_pca = do_gridsearch_with_cv(clf_rf, RANDOM_FOREST_PARAMS, X_train_pca, y_train_pca, kf, smote=None)\n",
    "gss_raw = [gs_full, gs_red, gs_pca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
